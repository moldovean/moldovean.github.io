<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title> AI Intro </title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/black.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
    <!-- Prims for code highlighting -->
    <link rel="stylesheet" href="css/endava.css">
    <link rel="stylesheet" href="css/prism.css">
    <script type="text/javascript" src="js/prism.js"></script>
</head>

<body>

<div class="reveal">

    <img class="endava-logo" src="pics/endava-ico.png"/>

    <div class="slides">


        <!-- Slide Intro and Contents -->
        <section>
            <!-- Name -->
            <section>
                <h2>Intro to <abbr title="Artificial Intelligence">AI </abbr>: <abbr
                        title="Ordinary Leas Squares">OLS</abbr> <abbr title="Neural Networks">NN</abbr> & <abbr
                        title="Hidden Markov Model">HMM </abbr></h2>
                <p> Authors: Gleb Godonoga & Me</p>
                <p> Advisers: Dumitru Cadea & Mircea Sirghi & Alexandru Lazari</p>

            </section>

            <!-- Contents -->
            <section>
                <h2>Contens:</h2>
                <ul>

                    <li> Introduction to OLS</li>
                    <li> Logistic Regression</li>
                    <li> The Feed Forward Neural Networks</li>
                    <hr/>
                    <li> Discrete State Markov Chains</li>
                    <li> Workshop on Neural Networks</li>
                    <li> Feed Forward</li>
                    <li> Continuous State Space Markov Chains</li>
                    <li> Hidden Markov Models</li>
                </ul>

            </section>


            <!-- OLS -->
            <section>
                <h3> Part I: Introduction to OLS </h3>
                <ol>
                    <li> Early methods of Prediction</li>
                    <li> Correlation</li>
                    <li> Ordinary Least Squares (OLS)</li>
                </ol>
            </section>

            <!-- Part 2: Logistic Regression  -->
            <section>
                <h3> Part II: Logistic Regression </h3>
                <ol>
                    <li> Sigmoid Function</li>
                    <li> Logistic Regression</li>
                </ol>
            </section>

            <!-- Part III: The Feed Forward Neural Networks-->
            <section>
                <h3> Part III: The Neural Networks</h3>
                <ol>
                    <li> Feed Forward Neural Networks</li>
                    <li>
                        <del> Recurrent Neural Networks (RNN)</del>
                    </li>
                    <li>
                        <del> Convolutional Neural Networks (CNN)</del>
                    </li>
                    <li>
                        <del> Radial Basis Neural Networks (RBNN)</del>
                    </li>
                </ol>
            </section>


            <!-- Applications of Discrete State Markov Chains in Economics -->
            <section>
                <h3> Part IV: Markov Chains </h3>
                <ol>
                    <li> First Order Markov Chain</li>
                    <li> Stationary Distribution</li>
                    <li> Simulating a Markov Chain</li>
                    <li> Second and N-order Markov Processes</li>
                </ol>
            </section>


        </section>


        <!--OLS-->
        <section>
            <!-- OLS -->
            <section>
                <h3> Part I: Introduction to OLS </h3>
                <ol>
                    <li> Early methods of Prediction</li>
                    <li> Correlation</li>
                    <li> Ordinary Least Squares (OLS)</li>
                </ol>
            </section>

            <section>
                <h3>Correlatioin</h3>
                <p> What is correlation? </p>
                <p class="fragment">$$\rho = \frac{\text{cov}(X,Y)}{\sigma_x \sigma_y}$$</p>
                <p class="fragment"> What is Covariance? / SD? </p>
                <p class="fragment">$$E[(x_i - \overline{x})(y_i - \overline{y})] = \frac{1}{n} \sum_{i=1}^{n} (x_i -
                    \overline{x})(y_i - \overline{y})$$</p>
                <p class="fragment">$$r = \frac{{}\sum_{i=1}^{n} (x_i - \overline{x})(y_i - \overline{y})}
                    {\sqrt{\sum_{i=1}^{n} (x_i - \overline{x})^2(y_i - \overline{y})^2}}$$</p>

            </section>
            <section>
                <p>$$Y_i = \beta_0 + \beta_1 X_1i \epsilon_i$$</p>
                <p>$$Y_i = \beta_0 + \beta_1 X_1i + \beta_2 X_2i \epsilon_i$$</p>
                <p>Estimation:</p>
                <p>$$\hat{Y}_i = \hat{\beta}_0 + \hat{\beta}_1 X_i + \hat{\epsilon}_i$$</p>
            </section>


            <section>
                <iframe class="stretch" src="http://setosa.io/ev/ordinary-least-squares-regression/"></iframe>

            </section>

            <section>
                <h3>Gradient Descent Panacea</h3>

            </section>

        </section>


        <!--History of Ai-->
        <section>

            <section>
                <h3>Walter Pitts & McCulloch</h3>
                <ol>
                    <li class="fragment"> Seminal Paper: "A Logical Calculus of Ideas Immanent in Nervous Activity"
                        (1943) Walter Pitts & McCulloch, Bulletin of Mathematical Biophysics.
                    </li>

                    <ul>
                        <li class="fragment"> Fresh from reading a new paper by Alan Turing which proved the possibility
                            of a machine that could compute any function
                        </li>
                        <li class="fragment"> McCulloch became convinced that the brain was just such a machine</li>
                        <li class="fragment"> Introduced the so-called perceptron (neuron), known as McCulloch–Pitts <a
                                href="https://en.wikipedia.org/wiki/Artificial_neuron">(MCP) neuron</a></li>

                    </ul>

                </ol>
            </section>

            <section>
                <h3>History of AI</h3>
                <p><i>"we know how we know..."</i></p>
                <ul>
                    <li class="fragment"> Principa Matematica by Russell and Whitehead</li>
                    <ul>
                        <li class="fragment">all of mathematics could be built from the ground up using basic,
                            indisputable logic
                        </li>
                    </ul>
                    <li class="fragment">Walter Pitts b. 1923 & Warren Sturgis McCulloch b. 1898</li>
                    <ol>
                        <li class="fragment"> Principa Matematica: 3 days for Pitts at age 12</li>
                        <li class="fragment"> At 15 Pitts finds out Russell is coming to U. of Chicago, runs away from
                            home
                        </li>
                        <li class="fragment"> meets Jerome Lettvin during Math classes</li>
                        <li class="fragment"> Jerome Lettvin - introduces Pitts to McCulloch</li>
                    </ol>
                </ul>
            </section>

            <section>
                <h3>History of AI</h3>
                <p><i>"we know how we know..."</i></p>
                <p>McCulloch is fascinated by Pitts. They both shared the passion for Principa Matematica.
                    Pitts helps McCulloch formalize the myriad of his ideas into rigurous mathematical functions.</p>
                <p class="fragment">McCulloch had very crisp ideas how a neuron might function but lacked the
                    mathematical skills.</p>
                <p class="fragment">McCulloch invites Pitts to move with his family.</p>
                <p class="fragment"> Seminal Paper: "A Logical Calculus of Ideas Immanent in Nervous Activity" (1943)
                    Walter Pitts & McCulloch, Bulletin of Mathematical Biophysics.</p>

            </section>

            <section>
                <h3> yet more events: </h3>
                <ol>
                    <li>Lettvin brought Pitts to: Norbert Wiener at MIT</li>
                    <li>They did not even introduce over small talk... straight to math</li>
                    <li>Wiener would later write that Pitts was “without question the strongest young scientist whom I
                        have ever met..."
                    </li>
                </ol>
                <p class="fragment">Wiener figured that if Pitts was going to make a realistic model of the brain’s 100
                    billion interconnected neurons, he was going to need statistics on his side. And statistics and
                    probability theory were Wiener’s area of expertise. </p>
            </section>

            <section>
                <p> His work with Wiener was :</p>
                <p class="fragment"> “to constitute the first adequate discussion of statistical mechanics, understood
                    in the most general possible sense, so that it includes for example the problem of deriving the
                    psychological, or statistical, laws of behavior from the microscopic laws of neurophysiology …
                    Doesn’t it sound fine?”</p>
            </section>

            <section>
                <h3> Pitts goes to Princeton: </h3>
                <p class="fragment"> John von Neumann meets Pitts </p>
                <p class="fragment"> ... equally impressed</p>
                <p class="fragment">The following June, 1945, von Neumann penned what would become a historic document
                    entitled “First Draft of a Report on the EDVAC,” the first published description of a stored-program
                    binary computing machine—the modern computer.</p>
            </section>

            <section>
                <h3>The modern computer arhitecture </h3>
                <p> To accomplish this, von Neumann suggested modeling the computer after Pitts and McCulloch’s neural
                    networks. In place of neurons, he suggested vacuum tubes, which would serve as logic gates, and by
                    stringing them together exactly as Pitts and McCulloch had discovered, you could carry out any
                    computation. To store the programs as data, the computer would need something new: a memory. That’s
                    where Pitts’ loops came into play. “An element which stimulates itself will hold a stimulus
                    indefinitely,” von Neumann wrote in his report, echoing Pitts and employing his modulo mathematics.
                    He detailed every aspect of this new computational architecture. In the entire report, he cited only
                    a single paper: “A Logical Calculus” by McCulloch and Pitts. </p>
            </section>

            <section>
                <h3>Seminal Papers: </h3>
                <li>"What the Frog's Eye Tells the Frog's Brain" (1959) Pitts & Lettvin</li>
                <ul>
                    <li> one of the most cited papers in the Science Citation Index</li>
                    <li> McCulloch, Humberto Maturana, Oliver Selfridge also contributed</li>
                </ul>
            </section>

            <section>
                <h4>The first AI group</h4>
                <ul>
                    <li>
                        A group was established with Wiener, Pitts, McCulloch, Lettvin, and John von Neumann.
                    </li>
                    <li>
                        <ul>
                            <li> Wiener's wife did not like Mcculloch and his promiscuous nature</li>
                            <li> Pitts started work on a dissertation on the properties of neural nets connected in
                                three
                                dimensions...
                            </li>
                            <li> Lettvin described Pitts as "in no uncertain sense the genius of the group … when you
                                asked him a question, you would get back a whole textbook".
                            </li>
                            <li> McCulloch : promiscuous -> invented LISP programming language</li>
                            <li> Lettvin : vocal and politically active, against the use of LCD and other recreational
                                drugs, IG Nobel Prize winner
                            </li>
                        </ul>
                    </li>
                </ul>
            </section>

        </section>


        <!--BackPropagation-->
        <section>
            <section>
                <h1>What is a neuron</h1>
                <p>$$z_j = b_j + \sum_i a_i w_{ij}$$</p>
                <p>$$ h_ \theta (x) =  \frac{\mathrm{1} }{\mathrm{1} + e^{- z_j} }  $$ </p>
                <p>$$\theta = \{\mathbf{W},\mathbf{b}\}$$</p>
                
            </section>

            <section>
                <div style="background: white">
                    <img src="https://i.stack.imgur.com/76Kuo.png" alt="enter image description here">
                </div>
            </section>

            <section>
                <p>we need to find the rate of change of the error with respect to the change in weight for a given weight.</p>
                <p>$$E_k = \frac{1}{2} (d - y_k)^2 $$</p>
                <p>$$V_L = \sum\limits_{A,B \epsilon S} w_{ABmn} y_{Am} $$</p>
                <p>$$y_L = \sigma(V_L) $$</p>
                <p>$$\Delta w = - \eta \frac{\partial E_k}{\partial w_{ABmn}} $$</p>
            </section>

        </section>


        <!-- Markov Chains -->
        <section>
            <section>
                <h1>Why study Markov Chains? </h1>
                <blockquote>
                    Jeffrey Kuan at Harvard University claimed that Markov models might well be the most “real world”
                    useful mathematical concept after that of a derivative.
                </blockquote>
            </section>
            <section>
                <h2>Why study Markov Chains? </h2>

                <p> Markovian processes are used in:
                <ul>
                    <li> algorithmic music composition</li>
                    <li><a href="https://en.wikipedia.org/wiki/PageRank"> google search engine (Page Rank) </a></li>
                    <li> asset pricing models</li>
                    <li> information processing</li>
                    <li> computer malware detection</li>
                    <li> speech recognition</li>
                    <li> nucleotide sequencing</li>
                    <li><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0034637"> lung
                        cancer </a></li>
                    <li> and many more</li>
                </ul>
                </p>

            </section>


            <section>
                <h2> History of Markov Chains </h2>
                Andrey Markov wanted to disprove Nekrasov's claim that only independet events could converge on
                predictable distributions.
            </section>

            <section>
                <h5>History of Markov Chains from 4m10s</h5>
                <iframe class="stretch" src="http://www.youtube.com/embed/o-jdJxXL_W4"></iframe>
            </section>

            <section>
                <h5>First Order Markov Chain in Music</h5>
                <iframe class="stretch" src="http://www.youtube.com/embed/4Gi-TucPQlc"></iframe>
            </section>


        </section>


        <!-- Formal intro of a Markov Chain -->
        <section>
            <section>
                <h1>What is a Markov Chain?</h1>

            </section>

            <section data-autoslide="4000">
                <h2>A Markov Chain is:</h2>
                <p class="fragment"> a dynamic stochastic process with a <em>Markovian Property</em></p>.
                <h4 class="fragment" data-autoslide="4000"> What is a <em>Markovian Property</em>? </h4>
                <span class="fragment">$Pr\left(X_t = x_i |X_{t-1},X_{t-2},...,X_{1}  \right) = Pr\left( X_t=x_i|X_{t-1} \right)$</span>
                <span class="fragment" data-autoslide="8000"></span>


            </section>
            <section>
                <h3>First order Markov Chain?</h3>
                <iframe class="stretch"
                        src="http://setosa.io/markov/index.html#%7B%22tm%22%3A%5B%5B0.3%2C0.3%2C0.4%5D%2C%5B0.3%2C0.5%2C0.2%5D%2C%5B0.4%2C0.4%2C0.2%5D%5D%7D"></iframe>
            </section>

            <section>
                <h3>First order Markov Chain?</h3>
                <iframe background-color="transparent" class="stretch"
                        src="http://setosa.io/markov/index.html#%7B%22tm%22%3A%5B%5B0.2%2C0.2%2C0%2C0.2%2C0.3%2C0%2C0.1%5D%2C%5B0.9%2C0%2C0%2C0%2C0%2C0%2C0.1%5D%2C%5B0%2C0.8%2C0%2C0.2%2C0%2C0%2C0%5D%2C%5B0%2C0.2%2C0.3%2C0.3%2C0%2C0%2C0.2%5D%2C%5B0%2C0.2%2C0.3%2C0%2C0%2C0.4%2C0.1%5D%2C%5B0.3%2C0.1%2C0%2C0%2C0.1%2C0.2%2C0.3%5D%2C%5B0%2C0.1%2C0%2C0%2C0%2C0.1%2C0.8%5D%5D%7D"></iframe>
            </section>

        </section>

        <!--  Applications of Markov Chains in Economics -->
        <section>
            <section>
                <h1> Applications of Markov Chains in Economics </h1>
            </section>
            <section>
                <h3> Applications of Markov Chains in Economics </h3>
                <p> From Hamilton, Economic Transition </p>
                $$\mathbb{A} = \left( \begin{array}{ccc}
                0.971 & 0.029 & 0 \\
                0.145 & 0.778 & 0.077 \\
                0 & 0.508 & 0.492
                \end{array} \right) $$
                <p>With the followint payoffs</p>
                $$\mathbb{E} = \left( \begin{array}{c}
                0.215 \\
                0.015 \\
                -0.18 \\
                \end{array} \right)$$
            </section>
            <section>
                <h4>The Hamilton Matrix simulation</h4>
                <iframe class="stretch"
                        src="http://setosa.io/markov/index.html#%7B%22tm%22%3A%5B%5B0.971%2C0.029%2C0%5D%2C%5B0.145%2C0.778%2C0.077%5D%2C%5B0%2C0.508%2C0.492%5D%5D%7D"></iframe>
                <p class="fragment"> But We will do this later! </p>
            </section>
            <section>
                <h4>Find Eigenvalues and Eigenvectors of $\mathbb{A}$</h4>
                $$\left| \mathbb{A}-I\lambda \right| = \left| \begin{array}{ccc}
                0.971-\lambda & 0.029 & 0 \\
                0.145 & 0.778-\lambda & 0.077 \\
                0 & 0.508 & 0.492-\lambda
                \end{array} \right| =0$$
                <p class="fragment"> This gives us: </p>
                <span class="fragment">
						$$
						\mathbf{\lambda} = \left(\begin{array}{c}
               1.00000 \\
               0.85157 \\
               0.38943 \\
            \end{array} \right)
						$$
						<p class="fragment">Then find the null space for each eigenvalue</p>
						</span>
            </section>
            <section>
                <h4> We can now calculate the expected payoff conditional on $\mu$</h4>
                $$\mathbf{S}\mathbf{\Lambda}^{25}\mathbf{S}^{-1} = \left(\begin{array}{ccc}
                0.816125 &0.159822 &0.024054 \\
                0.799109 &0.173836 &0.027055 \\
                0.793458 &0.178491 &0.028051 \\
                \end{array}\right)$$
            </section>

            <section>
                <h4>Simulating Marathon Oil Returns </h4>
                <iframe allowfullscreen class="stretch" data-src="iframes/MCSimulation.html" width="645"
                        height="655"></iframe>
            </section>

        </section>

        <!-- A lil bit of theory -->
        <section>
            <section>
                <h1> A little bit of Theory </h1>
            </section>
            <section>
                <h4> Irreducible Stochastic Matrices </h4>
                <p>A stochastic matrix, <span class="math inline">\(\mathbb{A}\)</span> is <strong>irreducible</strong>
                    if its graph is strongly connected, that is: there <span
                            class="math inline">\(\exists \; t \geq 0\)</span> : <span class="math inline">\(Pr(X_{t}=j|X_{0}=i) &gt; 0 \)</span>
                </p>
                <p> In our example, $\mathbb{A}$ is irreducible since we can end up in any state from any state after
                    <span class="math inline">\(t \geq 1\)</span> steps.</p>
            </section>
            <section>
                <h4 id="aperiodic-stochastic-matrices">Aperiodic Stochastic Matrices</h4>
                <p>A stochastic matrix, <span class="math inline">\(\mathbb{A}\)</span> is <strong>aperiodic</strong> if
                    the greatest common divisor of the set S(x) defined as <span class="math display">\[S(x) = \{t \geq 1 : P^t(x, x) &gt; 0\}\]</span>
                    equals 1.</p>
                <p>We can easily check that matrix <span class="math inline">\(\mathbb{A}\)</span> from our example is
                    aperiodic.</p>
            </section>
            <section>
                <h4 id="stationary-distribution">Stationary Distribution</h4>
                <p>A probability distribution <span class="math inline">\(\pi\)</span> over <span class="math inline">\(X\)</span>
                    is <strong>stationary</strong> over <span class="math inline">\(\mathbb{A}\)</span> if: <span
                            class="math display">\[\pi = \pi \mathbb{A}\]</span></p>
            </section>
            <section>
                <h4>Fundamental Theorem of Markov Chains</h4>
                A theorem proven by <span class="citation">Häggström (2002)</span> states that:</p>
                <p>[Fundamental Theorem of Markov Chains][Haggstrom] If a stochastic matrix <span class="math inline">\(\mathbb{A}\)</span>
                    is irreducible and aperiodic then there is a unique probability distribution <span
                            class="math inline">\(\pi\)</span> that is stationary on <span class="math inline">\(\mathbb{A}\)</span>.
                </p>
                <p>provided by <span class="citation">Häggström (2002)</span>.</p>
                <p class="fragment"> Therefore, we can write: $$\lim_{t \to \infty} \mu \mathbb{A}^t = \pi$$</p>

            </section>
            <section>
                <p> Since all but one of the eigenvalues is smaller than unity. </p>
                $$\mathbf{\phi} = \lim_{t \to \infty} \mathbf{S}\Lambda^t\mathbf{S}^{-1} = \mathbf{S}
                \left(\begin{array}{ccc}
                1 &0 &0 \\
                0 &0 &0 \\
                0 &0 &0 \\
                \end{array}\right) \mathbf{S}^{-1}$$
                <p class="fragment"> in our example: </p>
                <span class="fragment">$$\phi = \left(\begin{array}{c}
          0.812800, 0.162560,  0.024640\\
          \end{array} \right)$$ </span>
            </section>


        </section>

        <!-- Hidden Markov Model -->
        <section>
            <section>
                <h1>The Hidden Markov Model</h1>
            </section>
            <section>
                <h2 id="HMM">The Hidden Markov Model </h2>

                <div class="figure">
                    <img src="graphs/HMM.jpg" alt="Hidden Markov Model from pp.9Fraser (2008, 9)" style="width:95.0%"/>
                    <p class="caption">Hidden Markov Model from <span class="citation">Fraser (2008, 9)</span><span
                            data-label="fig:HMM"></span></p>
                </div>
                <p> we have an oriented graph which can easily be transposed to a HMM model.</p>

            </section>

            <section>
                <h3>The Hidden Markov Model</h3>
                <p>
                    $$\mathbb{A} = \begin{array}{c} e \\ f \\ g \\ h \end{array} \left( \begin{array}{cccc}
                    0.9 &amp; 0.1&amp; 0 &amp; 0 \\
                    0 &amp; 0 &amp; 1 &amp; 0 \\
                    0 &amp; 0 &amp; 0.9&amp; 0.1 \\
                    1 &amp; 0 &amp; 0 &amp; 0 \end{array} \right)$$</p>

                <p>The emission probabilities for the events <span class="math inline">\(\Sigma = \{a,b,c,d\}\)</span>,
                    as specified in the [smc]: <span class="math display">\[\mathbb{B} =
			            \begin{array}{c} e \\ f \\ g \\ h \end{array}
			            \begin{pmatrix}
			            0.1 &amp; 0.9 &amp; 0 &amp; 0 \\
			            0   &amp; 1   &amp; 0 &amp; 0 \\
			            0 &amp; 0.8 &amp; 0.2 &amp; 0 \\
			            0 &amp; 0&amp; 0&amp; 1
			            \end{pmatrix}\]</span></p>
                <p> An initial probability distribution among the states $\pi$</p>

            </section>

            <!-- Formally defining the HMM -->
            <section>
                <h2>The Hidden Markov Model</h2>
                <p>Formally we define an HMM $\lambda(\mathbb{A,B},\pi)$</p>
                <p>Parameters, $\mathbb{A,B},\pi$ are often denoted by $\theta$, thus $\lambda(\theta)$ </p>

            </section>

            <section>
                <h2>Simulating a Hidden Markov Model</h2>
                <p> Using external libraries <a href="http://ghmm.org" class="uri">http://ghmm.org</a>.</p>

                $$\mathbb{A}= \left(\begin{array}{cc}
                0.9 &amp; 0.1 \\
                0.2 &amp; 0.8 \\
                \end{array}\right)$$
                <p>Emissions: one fair coin and one biased</p>
                $$\mathbb{B}= \left(\begin{array}{cc}
                0.5 &amp; 0.5 \\
                0.15 &amp; 0.85 \\
                \end{array}\right)$$

                <p>Outcomes: <em> Head (0)</em> or <em>Tail (1)</em>. </p>
                <p>[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,
                    0, 0, 1, 1, 0, 1, 0 ...</p>
                <p>The code is provided in the Annex</p>
            </section>


        </section>

        <!-- Part I The Baum Welch Algorithm -->
        <section>
            <section>
                <h1>Forward, Backward and Viterbi Algorithm</h1>
            </section>

            <section>
                <h3>Estimating $\lambda(\mathbb{A,B},\pi)$</h3>
                <p class="fragment">Before we estimate $\lambda$, it is helpful to answer the following questions:</p>
                <dl>
                    <dt class="fragment"> Evaluation: $Pr(\mathcal{O}|\lambda)=?$</dt>
                    <dd class="fragment">- Use the Forward in combination with Backward algorithm</dd>
                    <dt class="fragment"> Decoding: Most likelihood sequence of states $ \texttt{argmax}_{\mathcal{X}}
                        Pr(\mathcal{O}|\mathcal{X},\lambda)=?$
                    </dt>
                    <dd class="fragment">- Viterbi algorithm</dd>
                    <dt class="fragment"> Learning: estimate $\lambda$</dt>
                    <dd class="fragment">- Use the <em>Bayesian rule</em> along with the <em>Markovian property</em> to
                        update the parameters of the HMM: Baum-Welch algorithm.
                </dl>

            </section>

            <section>
                <h3>Probability of $\mathcal(O|\lambda)$</h3>
                <p>Suppose we have identified a sequence <span
                        class="math inline">\(\mathcal{O} \in \mathbf{\Omega}\)</span> that we assume is generated by an
                    HMM: <span class="math inline">\(\lambda(\mathbb{A},\mathbb{B},\pi)\)</span>. Given <span
                            class="math inline">\(\lambda\)</span>, we would like to know: <span class="math display">\[Pr(\mathcal{O}|\lambda)=?\]</span>
                </p>

            </section>

            <section>
                <h3>Direct approach</h3>
                <p>Given a model $\lambda$ a sequence of observations $o_1, o_2, ...$ and states $x_1, x_2, ...$</p>
                <span class="fragment">$$Pr\left(o_1,o_2,...,o_{T} |x_1,x_2,...,x_k,...x_T, \lambda \right)=  \pi_i b_i(o_1) \prod_{t=2}^{t=T} a_{t-1,t}b_{a_t}(o_t)$$</span>
                <p class="fragment">We then sum over all possible states</p>
                <span class="fragment">$$Pr\left(\mathcal{O} | \lambda \right)= \sum_X  \pi_i b_i(o_1) \prod_{t=2}^{t=T} a_{t-1,t}b_{a_t}(o_t) Pr(X|\lambda)$$</span>
            </section>

            <section>
                <h3><span class="math display">\[Pr(\mathcal{O}|\lambda)=?\]</span></h3>
                <p>The difficulty of this approach is that the total number of possibilities of sequences of states that
                    can generate <span class="math inline">\(\mathcal{O}\)</span> is exponential in the number of
                    observations <span class="math inline">\(T\)</span></p>
                $$Pr\left(\mathcal{O} | \lambda \right)= \sum_X \pi_i b_i(o_1) \prod_{t=2}^{t=T} a_{t-1,t}b_{a_t}(o_t)
                Pr(X|\lambda)$$
            </section>

            <section>
                <h3><span class="math display">\[Pr(\mathcal{O}|\lambda)=?\]</span></h3>
                <p>A better approach to calculate the unconditional probability <span class="math inline">\(Pr(\mathcal{O}|\lambda)\)</span>
                    is the forward/backward algorithm which is a class of dynamic programming algorithms and takes
                    advantage of the assumptions of the Markovian processes to filter all possible combinations of
                    states <span class="math inline">\(X\)</span>.</p>
            </section>

            <!-- Forward Backward decomposition -->
            <section>
                <h3>The Forward/Backward decomposition</h3>
                <p>the objective of the forward/backward algorithm is to compute the probability of being in a
                    particular state <span class="math inline">\(x_t\)</span> at time <span
                            class="math inline">\(t\)</span>, given a sequence of observations <span
                            class="math inline">\(\mathcal{O}\)</span></p>
                $$Pr(x_k | \mathcal{O})= ? , k \in \{1..T \}$$
            </section>
            <section>
                <h3>The Forward/Backward decomposition</h3>
                <p>$$Pr(x_k | \mathcal{O}, \mathbf{\lambda}) = \frac{Pr(x_k, \mathcal{O} |
                    \mathbf{\lambda})}{Pr(\mathcal{O}|\mathbf{\lambda})} = $$</p>
                <p class="fragment">$$\frac{Pr(x_k,o_1,o_2,...o_k |\mathbf{\lambda}
                    )*Pr(o_{k+1},...,o_T|x_k,o_1,...o_k,\mathbf{\lambda})}{Pr(\mathcal{O}|\mathbf{\lambda})}$$</p>
                <p class="fragment">using the Markovian property:</p>
                <p class="fragment">$$Pr(x_k | \mathcal{O}, \mathbf{\lambda}) = \frac{Pr(x_k,o_1,o_2,...o_k
                    |\mathbf{\lambda} )
                    Pr(o_{k+1},...,o_T|x_k,\mathbf{\lambda})}{Pr(\mathcal{O}|\mathbf{\lambda})}$$</p>
            </section>
            <!-- alpha -->
            <section>
                <h3>The Forward/Backward decomposition</h3>
                We denote:
                $$\alpha_i(k)=\alpha\left( x_k=i \right) = Pr(o_1,o_2,...o_k,x_k | \lambda) \quad\quad o_k \in
                \mathcal{O}, k=\overline{1,T}$$
                $$\beta_i(k)=\beta(x_k=i) = Pr(o_{k+1},o_{k+2},...,o_{T} | x_k=i, \lambda) \quad i=\overline{1,N},
                k=\overline{1,T}$$
                <p class="fragment">$$Pr(x_k=i | \mathcal{O}, \mathbf{\lambda}) = \frac{\alpha_i(k)
                    \beta_i(k)}{Pr(\mathcal{O}|\mathbf{\lambda})} =$$</p>
                <p class="fragment">$$ \frac{\alpha_i(k) \beta_i(k)}{\sum_{i=1}^N \alpha_i(k=T)} $$</p>
            </section>
            <!-- Forward -->
            <section>
                <h3>The Forward algorithm</h3>
                \begin{aligned}
                \alpha_i\left( x_k \right) =& \sum_{x_{k-1}} Pr(o_1,o_2,...o_k,x_{k-1},x_k | \lambda) \\
                = &\sum_{x_{k-1}} Pr(o_k | o_1,o_2,...o_{k-1},x_{k-1},x_k, \lambda)\times
                \\&Pr(x_k|o_1,o_2,...o_{k-1},x_{k-1},\lambda) Pr(o_1,o_2,...o_{k-1},x_{k-1}|\lambda)
                \\ =& \sum_{x_{k-1}} Pr(o_k | x_k, \lambda)Pr(x_k|x_{k-1},\lambda) \alpha\left( x_{k-1} \right)
                \\ =& \sum_{x_{k-1}} \mathbf{b}_{x_k}(o_k) \mathbf{a}_{(k-1,k)}\alpha\left( x_{k-1} \right)
                \\ =& \mathbf{b}_{x_k}(o_k) \sum_{x_{k-1}} \mathbf{a}_{(k-1,k)}\alpha\left( x_{k-1} \right) , \quad
                x_{k-1}=\overline{1,N}, k=\overline{2,T}\end{aligned}
            </section>
            <!-- Backward -->
            <section>
                <h3>The Backward algorithm</h3>
                Similarly:
                $$\begin{aligned}
                \beta(x_k) &= \sum_{x_{k+1}}\beta(x_{k+1})\mathbf{b}_{k+1}(o_{k+1})\mathbf{a}_{k,k+1}, \quad\quad
                k=\overline{1,T-1}\end{aligned}$$
            </section>

            <!-- Viterbi -->
            <section>
                <h2>Decoding: The Viterbi Algorithm</h2>
                Given $\lambda$, our objective is:
                $$Pr\left(\mathcal{O}, x_1,x_2,...x_T,| \lambda \right)= \underset{X}{\operatorname{argmax}} \: \pi_i
                b_i(o_1) \prod_{t=2}^{t=T} a_{t-1,t}b_{a_t}(o_t)$$
                <span class="fragment">$$Pr(x_1=k|o_1,\lambda) = \frac{Pr(x_1=k,o_1)}{\sum_{x_1\in S}Pr(x_1,o_1)}= \frac{\pi_{x_1}b_{x_1}(o_1)}{\sum_{x_i \in S} \pi_{x_i}b_{x_i}(o_1)}$$</span>
                <span class="fragment">$$V_{1,k}=\pi_{x_k}b_{x_k}(o_1)$$ </span>
                <span class="fragment"> $$V_{t,k} = \underset{x_{t-1}\in S}{\operatorname{max}}\left( V_{t-1,x_{t-1}} \mathbf{a}_{x_{t-1},k} \mathbf{b}_{k}(o_t) \right)$$ </span>
            </section>


        </section>

        <!-- Baum Welch -->
        <section>

            <section>
                <h1>Baum Welch algorithm: estimating $\lambda$</h1>

            </section>
            <section>
                <p>Given an observable sequence <span class="math inline">\(\mathcal{O} = \{o_1,o_2,...,o_T \}\)</span>
                    and assuming this sequence was generated by an HMM model <span class="math inline">\(\lambda(\mathbb{A,B},\pi)\)</span>
                    we want to find out the most likely set of parameters of <span
                            class="math inline">\(\lambda\)</span> that generated the sequence
                    <span class="math inline">\(\mathcal{O}\)</span>.
                    we want to find out <span class="math inline">\(\theta\)</span> that maximizes the probability:</p>
                $$\theta^{\star} = \underset{\theta}{\operatorname{arg\, max}}Pr\left(\mathcal{O} |
                \lambda(\theta)\right)$$

            </section>

            <section>
                $$Pr\left(x_t=i|\mathcal{O},\lambda(\theta)\right) = \frac{\alpha_i(t) \beta_i(t)}{\sum_{j \in
                S}\alpha_j(t) \beta_j(t) }$$
                $$\gamma_i(t) = Pr\left(x_t=i|\mathcal{O},\lambda(\theta)\right)$$
            </section>

            <section>
                $$Pr(X_t=i,X_{t+1}=j|\mathcal{O},\lambda) =
                \frac{\alpha_i(t) a_{ij} b_j(o_{t+1}) \beta_j(t)}{Pr(\mathcal{O}|\lambda(\theta))}$$
                $$\xi_{ij}(t) = Pr(X_t=i,X_{t+1}=j|\mathcal{O},\lambda)$$
                $$\xi_{ij}(t) = \frac{\alpha_i(t) a_{ij} b_j(o_{t+1}) \beta_j(t+1)}
                {\sum_{i\in S}\sum_{j\in S} \alpha_i(t) a_{ij} b_j(o_{t+1}) \beta_j(t+1) }$$
            </section>

            <section>
                $$a_{ij} = \frac{\sum_{t=1}^{T-1}\xi_{ij}(t)}{\sum_{t=1}^{T-1} \gamma_i(t)}$$
                <p> Substituting:
                    <span class="fragment">$$\bar{a_{ij}} = \dfrac{  \dfrac{\alpha_i(t) a_{ij} b_j(o_{t+1}) \beta_j(t+1)}
                              {\sum_{i\in S}\sum_{j\in S} \alpha_i(t) a_{ij} b_j(o_{t+1}) \beta_j(t+1) }}
                              {\dfrac{\alpha_i(t) \beta_i(t)}{\sum_{j \in S}\alpha_j(t) \beta_j(t) }} $$ </span></p>

            </section>

            <section>
                $$\bar{\pi_i} = \gamma_1(i) = \frac{\alpha_i(1)\beta_i(1)}{\sum_{i \in S} \alpha_i(1)\beta_i(1) }$$

            </section>

            <section>
                $$\bar{b_i(o_k)} = \frac{\sum_{t \in T} \gamma_t(i) \mathbf{1}_{o_t=o_k}}{\sum_{t \in T} \gamma_t(i)}$$
                Leonard E. Baum and Eagon (1967): $\mathbb{P}(\mathcal{O}|\bar{\lambda} \geq
                \mathbb{P}(\mathcal{O}|\lambda)$
            </section>
            <section>
                <h5>example on nucleotides, assuming 2 states:</h5>
                <iframe class="stretch"
                        src="http://nbviewer.jupyter.org/github/moldovean/usm/blob/master/Thesis/scripts/Python/GHMM%20BW%201.ipynb"></iframe>
            </section>

        </section>

        <!-- Links -->
        <section>
            <section>
                <h1>There is much more:</h1>
                <p><a href="thesis.html" target="_blank">HTML: Applications of Homogeneous Markovian Processes in
                    Economics and Latent Parameters Estimation for Discrete State Hidden Markov Models</a></p>
                <p><a href="docs/thesis_main.pdf" target="_blank"> The PDF version (complete) </a></p>
                <p> This presentation: <a href="http://moldovean.github.io" target="_blank">moldovean.github.io</a></p>
                <p> replicate results : <a href="https://github.com/moldovean/usm/tree/master/Thesis" target="_blank">
                    github.com/moldovean/usm/tree/master/Thesis </a></p>
            </section>
            <section>
                <iframe class="stretch"
                        src="http://nbviewer.jupyter.org/github/moldovean/usm/blob/master/Thesis/scripts/Python/GHMM%20BW%201.ipynb"></iframe>
            </section>
            <section>
                <h1>Thank you for your attention!</h1>
            </section>
            <section>
                <iframe class="stretch" src="docs/thesis_main.pdf"></iframe>
            </section>
        </section>
        <!-- the end -->

    </div>
</div>


<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>

<script>
    // More info https://github.com/hakimel/reveal.js#configuration
    Reveal.initialize({
        history: true,
        parallaxBackgroundImage: 'pics/mandelbrot.jpg',
        parallaxBackgroundSize: '3840px 2160px',

        // More info https://github.com/hakimel/reveal.js#dependencies
        dependencies: [
            {src: 'plugin/markdown/marked.js'},
            {src: 'plugin/markdown/markdown.js'},
            {src: 'plugin/notes/notes.js', async: true},
            {
                src: 'plugin/highlight/highlight.js', async: true, callback: function () {
                    hljs.initHighlightingOnLoad();
                }
            },
            // MathJax
            {src: 'plugin/math/math.js', async: true}
        ]
    });
    Reveal.configure({slideNumber: 'h/v'});

</script>
</body>
</html>
