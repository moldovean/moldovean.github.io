<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title> Estimating Latent Parameters in Stochastic State Transition Matrices in HMMs </title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>

	<body>

		<div class="reveal">
			<div class="slides">

				<!-- Slide Intro and Contents -->
				<section>
					<!-- Name -->
					<section>
						<h2>Applications of Markovian Processes in Economics and Latent Parameters Estimation in <abbr title="Hidden Markov Model">Hidden Markov Models</abbr></h2>
						<p> Author: Adrian@Vrabie.net </p>
						<p> Adviser: Dr. Habil. Univ Professor Dmitrii Lozovanu </p>

					</section>

					<!-- Contents -->
					<section>
						<h2>Contens:</h2>
						<ol>

							<li> Introduction	</li>
							<li> Applications of Discrete State Markov Chains in Economics</li>
							<li> Continuous State Space Markov Chains	</li>

							<li> Part II: Estimating the State Transition Matrix </li>
							<li> Code Implementation </li>

						</ol>

					</section>

					<!-- Introduction -->
					<section>
						 <h3> Introduction </h3>
							<ol>
								<li class="fragment"> Why study Markov Chains? </li>
								<li class="fragment"> What are Markovian Processes? </li>
								<li class="fragment"> What types of questions can we answer using Markov Chains? </li>
							</ol>
					</section>

					<!-- Applications of Discrete State Markov Chains in Economics -->
					<section>
						 <h3> Applications of Discrete State Markov Chains in Economics </h3>
							<ol>
								<li>First Order Markov Chain </li>
								<li> Stationary Distribution </li>
								<li> Simulating a Markov Chain </li>
								<li> Second and N-order Markov Processes </li>
							</ol>
					</section>

					<!-- Continuous State Markov Chains -->
					<section>
						<h3> Continuous State Markov Chains </h3>
							<ul>
								<li> Simulating a Continuous State Markov Chain </li>
								<li> Look Ahead Estimate </li>
							</ul>

					</section>

					<!-- Part II: Estimating the State Transition Matrix -->
					<section>
						<h2> Part II: Estimating the State Transition Matrix </h2>
							<ol>
								<li> The Hidden Markov Model </li>
								<li> Simulating a Hidden Markov Model </li>
								<li> The Forward/Backward Algorithm> </li>
								<li> The Viterbi Algorithm> </li>
								<li> The Baum Welch Algorithm </li>
							</ol>

					</section>

				</section>

				<!-- Introduction Presentation -->
				<section>
					<section>
						<h1>Why study Markov Chains? </h1>
						<blockquote>
							Jeffrey Kuan at Harvard University claimed that Markov models might well be the most “real world” useful mathematical concept after that of a derivative.
						</blockquote>
					</section>
					<section>
						<h2>Why study Markov Chains? </h2>

						<p> Markovian processes are used in:
						<ul>
							<li> algorithmic music composition </li>
							<li> <a href="https://en.wikipedia.org/wiki/PageRank"> google search engine </a> </li>
							<li> asset pricing models  </li>
							<li> information processing  </li>
							<li> machine learning </li>
							<li> computer malware detection </li>
							<li> speech recognition </li>
							<li> nucleotide sequencing </li>
							<li> <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0034637"> lung cancer </a> </li>
							<li> and many more </li>
						</ul>
					</p>

					</section>


					<section>
						<h2> History of Markov Chains </h2>
						Andrey Markov wanted to disprove Nekrasov's claim that only independet events could converge on predictable distributions.
					</section>

					<section>
						<h5>History of Markov Chains from 4m10s</h5>
						<iframe class="stretch" src="http://www.youtube.com/embed/o-jdJxXL_W4"></iframe>
					</section>

					<section>
						<h5>First Order Markov Chain in Music</h5>
						<iframe class="stretch" src="http://www.youtube.com/embed/4Gi-TucPQlc"></iframe>
					</section>


				</section>

				<!-- Formal intro of a Markov Chain -->
				<section>
					<section>
						<h1>What is a Markov Chain?</h1>

					</section>

					<section data-autoslide="4000">
						<h2>A Markov Chain is:</h2>
						<p class="fragment"> a dynamic stochastic process with a <em>Markovian Property</em> </p>.
						<h4 class="fragment" data-autoslide="4000"> What is a <em>Markovian Property</em>? </h4>
						<span class="fragment">$Pr\left(X_t = x_i |X_{t-1},X_{t-2},...,X_{1}  \right) = Pr\left( X_t=x_i|X_{t-1} \right)$</span>
						<span class="fragment" data-autoslide="8000"></span>


					</section>

					<section>
						<h3>First order Markov Chain?</h3>
						<iframe class="stretch" src="http://setosa.io/markov/index.html#%7B%22tm%22%3A%5B%5B0.3%2C0.3%2C0.4%5D%2C%5B0.3%2C0.5%2C0.2%5D%2C%5B0.4%2C0.4%2C0.2%5D%5D%7D"> </iframe>
					</section>

					<section>
						<h3>First order Markov Chain?</h3>
						<iframe background-color="transparent" class="stretch" src="http://setosa.io/markov/index.html#%7B%22tm%22%3A%5B%5B0.2%2C0.2%2C0%2C0.2%2C0.3%2C0%2C0.1%5D%2C%5B0.9%2C0%2C0%2C0%2C0%2C0%2C0.1%5D%2C%5B0%2C0.8%2C0%2C0.2%2C0%2C0%2C0%5D%2C%5B0%2C0.2%2C0.3%2C0.3%2C0%2C0%2C0.2%5D%2C%5B0%2C0.2%2C0.3%2C0%2C0%2C0.4%2C0.1%5D%2C%5B0.3%2C0.1%2C0%2C0%2C0.1%2C0.2%2C0.3%5D%2C%5B0%2C0.1%2C0%2C0%2C0%2C0.1%2C0.8%5D%5D%7D"> </iframe>
					</section>

				</section>

				<!--  Applications of Markov Chains in Economics -->
				<section>
					<section>
						<h1> Applications of Markov Chains in Economics </h1>
					</section>
					<section>
						<h3> Applications of Markov Chains in Economics </h3>
						<p> From Hamilton, Economic Transition </p>
						$$\mathbb{A} = \left( \begin{array}{ccc}
            0.971 & 0.029 & 0 \\
            0.145 & 0.778 & 0.077 \\
            0 & 0.508 & 0.492
            \end{array} \right) $$
						<p>With the followint payoffs</p>
						$$\mathbb{E} = \left( \begin{array}{c}
            0.215 \\
            0.015 \\
            -0.18 \\
            \end{array} \right)$$
					</section>
					<section>
						<h4>The Hamilton Matrix simulation</h4>
						<iframe class="stretch" src="http://setosa.io/markov/index.html#%7B%22tm%22%3A%5B%5B0.971%2C0.029%2C0%5D%2C%5B0.145%2C0.778%2C0.077%5D%2C%5B0%2C0.508%2C0.492%5D%5D%7D"> </iframe>
						<p class="fragment"> But We will do this later! </p>
					</section>
					<section>
						<h4>Find Eigenvalues and Eigenvectors of $\mathbb{A}$</h4>
						$$\left| \mathbb{A}-I\lambda \right| = \left| \begin{array}{ccc}
            0.971-\lambda & 0.029 & 0 \\
            0.145 & 0.778-\lambda & 0.077 \\
            0 & 0.508 & 0.492-\lambda
            \end{array} \right| =0$$
						<p class="fragment"> This gives us: </p>
						<span class="fragment">
						$$
						\mathbf{\lambda} = \left(\begin{array}{c}
               1.00000 \\
               0.85157 \\
               0.38943 \\
            \end{array} \right)
						$$
						<p class="fragment">Then find the null space for each eigenvalue</p>
						</span>
					</section>
					<section>
						<h4> We can now calculate the expected payoff conditional on $\mu$</h4>
						$$\mathbf{S}\mathbf{\Lambda}^{25}\mathbf{S}^{-1} = \left(\begin{array}{ccc}
               0.816125   &0.159822   &0.024054 \\
               0.799109   &0.173836   &0.027055 \\
               0.793458   &0.178491   &0.028051 \\
            \end{array}\right)$$
					</section>

				</section>

				<!-- A lil bit of theory -->
				<section>
					<section>
						<h1> A little bit of Theory </h1>
					</section>
					<section>
						<h4> Irreducible Stochastic Matrices </h4>
						<p>A stochastic matrix, <span class="math inline">\(\mathbb{A}\)</span> is <strong>irreducible</strong> if its graph is strongly connected, that is: there <span class="math inline">\(\exists \; t \geq 0\)</span> : <span class="math inline">\(Pr(X_{t}=j|X_{0}=i) &gt; 0 \)</span></p>
						<p> In our example, $\mathbb{A}$ is irreducible since we can end up in any state from any state after <span class="math inline">\(t \geq 1\)</span> steps.</p>
					</section>
					<section>
						<h4 id="aperiodic-stochastic-matrices">Aperiodic Stochastic Matrices</h4>
	          <p>A stochastic matrix, <span class="math inline">\(\mathbb{A}\)</span> is <strong>aperiodic</strong> if the greatest common divisor of the set S(x) defined as <span class="math display">\[S(x) = \{t \geq 1 : P^t(x, x) &gt; 0\}\]</span> equals 1.</p>
						<p>We can easily check that matrix <span class="math inline">\(\mathbb{A}\)</span> from our example is aperiodic.</p>
					</section>
					<section>
						<h4 id="stationary-distribution">Stationary Distribution</h4>
          	<p>A probability distribution <span class="math inline">\(\pi\)</span> over <span class="math inline">\(X\)</span> is <strong>stationary</strong> over <span class="math inline">\(\mathbb{A}\)</span> if: <span class="math display">\[\pi = \pi \mathbb{A}\]</span></p>
					</section>
					<section>
						<h4>Fundamental Theorem of Markov Chains</h4>
						A theorem proven by <span class="citation">Häggström (2002)</span> states that:</p>
	          <p>[Fundamental Theorem of Markov Chains][Haggstrom] If a stochastic matrix <span class="math inline">\(\mathbb{A}\)</span> is irreducible and aperiodic then there is a unique probability distribution <span class="math inline">\(\pi\)</span> that is stationary on <span class="math inline">\(\mathbb{A}\)</span>.</p>
	          <p>provided by <span class="citation">Häggström (2002)</span>.</p>
						<p class="fragment"> Therefore, we can write: $$\lim_{t \to \infty} \mu \mathbb{A}^t = \pi$$</p>

					</section>
					<section>
						<p> Since all but one of the eigenvalues is smaller than unity. </p>
						$$\mathbf{\phi} = \lim_{t \to \infty} \mathbf{S}\Lambda^t\mathbf{S}^{-1} = \mathbf{S} \left(\begin{array}{ccc}
          1 &0 &0 \\
          0 &0 &0 \\
          0 &0 &0 \\
          \end{array}\right) \mathbf{S}^{-1}$$
					<p class="fragment"> in our example: </p>
					<span class="fragment">$$\phi = \left(\begin{array}{c}
          0.812800, 0.162560,  0.024640\\
          \end{array} \right)$$ </span>
					</section>

				</section>

			</div>
		</div>



		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,
				parallaxBackgroundImage: 'mandelbrot.png',
				parallaxBackgroundSize: '1920px 1080px',

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					// MathJax
        	{ src: 'plugin/math/math.js', async: true }
				]
			});
			Reveal.configure({ slideNumber: 'h/v' });

		</script>
	</body>
</html>
